{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: thefuzz in /usr/local/python/3.10.8/lib/python3.10/site-packages (0.20.0)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.0.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from thefuzz) (3.5.2)\n",
      "Requirement already satisfied: nltk in /usr/local/python/3.10.8/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /usr/local/python/3.10.8/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/codespace/.local/lib/python3.10/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/python/3.10.8/lib/python3.10/site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: spacy in /usr/local/python/3.10.8/lib/python3.10/site-packages (3.6.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from spacy) (8.1.12)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from spacy) (0.10.3)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from spacy) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from spacy) (4.64.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from spacy) (1.24.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/codespace/.local/lib/python3.10/site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from spacy) (2.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.10/site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/python/3.10.8/lib/python3.10/site-packages (from spacy) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.10/site-packages (from spacy) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/codespace/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.10/site-packages (from jinja2->spacy) (2.1.3)\n",
      "Requirement already satisfied: scispacy in /usr/local/python/3.10.8/lib/python3.10/site-packages (0.5.3)\n",
      "Requirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from scispacy) (3.6.1)\n",
      "Requirement already satisfied: scipy<1.11 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from scispacy) (1.10.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from scispacy) (2.31.0)\n",
      "Requirement already satisfied: conllu in /usr/local/python/3.10.8/lib/python3.10/site-packages (from scispacy) (4.5.3)\n",
      "Requirement already satisfied: numpy in /usr/local/python/3.10.8/lib/python3.10/site-packages (from scispacy) (1.24.2)\n",
      "Requirement already satisfied: joblib in /home/codespace/.local/lib/python3.10/site-packages (from scispacy) (1.3.2)\n",
      "Requirement already satisfied: nmslib>=1.7.3.6 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from scispacy) (2.1.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.3 in /home/codespace/.local/lib/python3.10/site-packages (from scispacy) (1.3.2)\n",
      "Requirement already satisfied: pysbd in /usr/local/python/3.10.8/lib/python3.10/site-packages (from scispacy) (0.3.4)\n",
      "Requirement already satisfied: pybind11<2.6.2 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from nmslib>=1.7.3.6->scispacy) (2.6.1)\n",
      "Requirement already satisfied: psutil in /home/codespace/.local/lib/python3.10/site-packages (from nmslib>=1.7.3.6->scispacy) (5.9.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->scispacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->scispacy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->scispacy) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->scispacy) (2023.7.22)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from scikit-learn>=0.20.3->scispacy) (3.2.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->scispacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->scispacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->scispacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->scispacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->scispacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->scispacy) (8.1.12)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->scispacy) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->scispacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->scispacy) (2.0.10)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->scispacy) (0.9.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->scispacy) (0.10.3)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->scispacy) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->scispacy) (4.64.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->scispacy) (2.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->scispacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/python/3.10.8/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->scispacy) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->scispacy) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->scispacy) (3.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->scispacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->scispacy) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/codespace/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->scispacy) (4.8.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->scispacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->scispacy) (0.1.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->scispacy) (8.1.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.10/site-packages (from jinja2->spacy<3.7.0,>=3.6.0->scispacy) (2.1.3)\n",
      "Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.3/en_core_sci_lg-0.5.3.tar.gz\n",
      "  Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.3/en_core_sci_lg-0.5.3.tar.gz (531.2 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.1 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from en-core-sci-lg==0.5.3) (3.6.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.1->en-core-sci-lg==0.5.3) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.1->en-core-sci-lg==0.5.3) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.1->en-core-sci-lg==0.5.3) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.1->en-core-sci-lg==0.5.3) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.1->en-core-sci-lg==0.5.3) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.1->en-core-sci-lg==0.5.3) (8.1.12)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.1->en-core-sci-lg==0.5.3) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.1->en-core-sci-lg==0.5.3) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.1->en-core-sci-lg==0.5.3) (2.0.10)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.1->en-core-sci-lg==0.5.3) (0.9.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.1->en-core-sci-lg==0.5.3) (0.10.3)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.1->en-core-sci-lg==0.5.3) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.1->en-core-sci-lg==0.5.3) (4.64.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.1->en-core-sci-lg==0.5.3) (1.24.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/codespace/.local/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.1->en-core-sci-lg==0.5.3) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.1->en-core-sci-lg==0.5.3) (2.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.1->en-core-sci-lg==0.5.3) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/python/3.10.8/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.1->en-core-sci-lg==0.5.3) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.1->en-core-sci-lg==0.5.3) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.1->en-core-sci-lg==0.5.3) (3.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.1->en-core-sci-lg==0.5.3) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.1->en-core-sci-lg==0.5.3) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/codespace/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.1->en-core-sci-lg==0.5.3) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.1->en-core-sci-lg==0.5.3) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.1->en-core-sci-lg==0.5.3) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.1->en-core-sci-lg==0.5.3) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.1->en-core-sci-lg==0.5.3) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.1->en-core-sci-lg==0.5.3) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.1->en-core-sci-lg==0.5.3) (0.1.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.1->en-core-sci-lg==0.5.3) (8.1.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.10/site-packages (from jinja2->spacy<3.7.0,>=3.6.1->en-core-sci-lg==0.5.3) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install thefuzz\n",
    "!pip install nltk\n",
    "!pip install spacy\n",
    "!pip install scispacy\n",
    "!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.3/en_core_sci_lg-0.5.3.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/codespace/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/spacy/language.py:2141: FutureWarning: Possible set union at position 6328\n",
      "  deserializers[\"tokenizer\"] = lambda p: self.tokenizer.from_disk(  # type: ignore[union-attr]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<scispacy.abbreviation.AbbreviationDetector at 0x7f8e9aebc520>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from load_data import load_ann, load_txt\n",
    "import pandas as pd\n",
    "from thefuzz import fuzz\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import spacy\n",
    "from scispacy.abbreviation import AbbreviationDetector\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "abreviation_handler = spacy.load(\"en_core_sci_lg\")\n",
    "abreviation_handler.add_pipe(\"abbreviation_detector\")\n",
    "\n",
    "\n",
    "abreviation_handler = spacy.load(\"en_core_sci_lg\")\n",
    "abreviation_handler.add_pipe(\"abbreviation_detector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full data path: /workspaces/codespaces-jupyter/Project/RawData/\n",
      "Time taken to read .txt files: 0.009160757064819336\n",
      "Time taken to read .ann files and extract all metadata: 0.12025904655456543\n"
     ]
    }
   ],
   "source": [
    "PATH_TO_ZIP = \"/workspaces/codespaces-jupyter/Project/RawData\"\n",
    "DATA_PATH = f\"{PATH_TO_ZIP}/\"\n",
    "print(f\"Full data path: {DATA_PATH}\")\n",
    "# read in txt files\n",
    "txt_df = load_txt(DATA_PATH)\n",
    "# read in REASONS entities from .ann files\n",
    "ent_df, rel_df = load_ann(DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txt_df shape: (303, 2)\n",
      "txt_df columns: Index(['file_idx', 'text'], dtype='object')\n",
      "txt_df head:\n",
      "   file_idx                                               text\n",
      "0   109450  Admission Date:  [**2121-8-7**]              D...\n",
      "1   103677  Admission Date:  [**2128-12-3**]              ...\n",
      "2   113824  Admission Date:  [**2200-6-14**]              ...\n",
      "3   113524  Admission Date:  [**2124-1-14**]              ...\n",
      "4   115244  Admission Date:  [**2168-4-18**]     Discharge...\n",
      "ent_df shape: (50951, 6)\n",
      "ent_df columns: Index(['file_idx', 'entity_id', 'category', 'start_idx', 'end_idx', 'text'], dtype='object')\n",
      "ent_df head:\n",
      "   file_idx entity_id  category start_idx end_idx             text\n",
      "0   120253        T1      Drug     10002   10015  Calcipotriene\\n\n",
      "1   120253        T2  Strength     10016   10021         0.005 \\n\n",
      "2   120253        T3      Form     10024   10029          Cream\\n\n",
      "3   120253        T4    Dosage     10035   10042        One (1)\\n\n",
      "4   120253        T5      Form     10043   10047           Appl\\n\n",
      "rel_df shape: (36348, 5)\n",
      "rel_df columns: Index(['file_idx', 'relationship_id', 'category', 'entity1', 'entity2'], dtype='object')\n",
      "rel_df head:\n",
      "   file_idx relationship_id       category  entity1    entity2\n",
      "0   120253              R1  Strength-Drug  Arg1:T2  Arg2:T1\\n\n",
      "1   120253              R2      Form-Drug  Arg1:T3  Arg2:T1\\n\n",
      "2   120253              R3    Dosage-Drug  Arg1:T4  Arg2:T1\\n\n",
      "3   120253              R4      Form-Drug  Arg1:T5  Arg2:T1\\n\n",
      "4   120253              R5     Route-Drug  Arg1:T6  Arg2:T1\\n\n"
     ]
    }
   ],
   "source": [
    "# EDA on txt_df\n",
    "print(\"txt_df shape:\", txt_df.shape)\n",
    "print(\"txt_df columns:\", txt_df.columns)\n",
    "print(\"txt_df head:\\n\", txt_df.head())\n",
    "\n",
    "# EDA on ent_df\n",
    "print(\"ent_df shape:\", ent_df.shape)\n",
    "print(\"ent_df columns:\", ent_df.columns)\n",
    "print(\"ent_df head:\\n\", ent_df.head())\n",
    "\n",
    "# EDA on rel_df\n",
    "print(\"rel_df shape:\", rel_df.shape)\n",
    "print(\"rel_df columns:\", rel_df.columns)\n",
    "print(\"rel_df head:\\n\", rel_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. Convert 'text' columns to lowercase, in order to facilitate comparison.\n",
    "\"\"\"\n",
    "# To lowercase 'text' column in ent_df\n",
    "ent_df['text'] = ent_df['text'].str.lower()\n",
    "ent_df['text'] = ent_df['text'].str.strip()\n",
    "\n",
    "# To lowercase 'text' column in txt_df\n",
    "# txt_df['text'] = txt_df['text'].str.lower()\n",
    "\n",
    "\"\"\"\n",
    "2. Remove \\n ending from 'text' column in ent_df and in 'entity2' column in rel_df.\n",
    "\"\"\"\n",
    "ent_df['text'] = ent_df['text'].str.rstrip('\\n')\n",
    "rel_df['entity2'] = rel_df['entity2'].str.rstrip('\\n')\n",
    "\n",
    "\"\"\"\n",
    "3. Convert 'start_idx' and 'end_idx' columns in ent_df to int.\n",
    "\"\"\"\n",
    "# Drop rows that cannot be converted to int TODO: Make this better\n",
    "ent_df = ent_df[ent_df['start_idx'].str.isnumeric()]\n",
    "ent_df = ent_df[ent_df['end_idx'].str.isnumeric()]\n",
    "ent_df['start_idx'] = ent_df['start_idx'].astype(int)\n",
    "ent_df['end_idx'] = ent_df['end_idx'].astype(int)\n",
    "\n",
    "# Make new column with lemmatized text of 'text' column called 'lemmatized_text'\n",
    "ent_df['orig_txt'] = ent_df['text']\n",
    "def lemmatize_text(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "ent_df['text'] = ent_df['text'].apply(lemmatize_text)\n",
    "ent_df['text'] = ent_df['text'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. Join the appropriate entity1 and entity2 for each relation in rel_df.\n",
    "\"\"\"\n",
    "# Remove first 5 letters from 'entity1' and 'entity2' column in rel_df\n",
    "rel_df['entity1'] = rel_df['entity1'].str[5:]\n",
    "rel_df['entity2'] = rel_df['entity2'].str[5:]\n",
    "rel_df = rel_df.merge(ent_df[['entity_id', 'text', 'file_idx']], how='left', left_on=['entity1', 'file_idx'], right_on=['entity_id', 'file_idx'])\n",
    "rel_df.rename(columns={'text': 'entity1_text'}, inplace=True)\n",
    "rel_df = rel_df.merge(ent_df[['entity_id', 'text', 'file_idx']], how='left', left_on=['entity2', 'file_idx'], right_on=['entity_id', 'file_idx'])\n",
    "rel_df.rename(columns={'text': 'entity2_text'}, inplace=True)\n",
    "rel_df.drop(columns=['entity_id_x', 'entity_id_y'], inplace=True)\n",
    "\n",
    "# Create column 'entity1_entity2' in rel_df\n",
    "rel_df['entity1_entity2'] = rel_df['entity1_text'] + rel_df['entity2_text']\n",
    "\n",
    "\"\"\"\n",
    "2. Get count of text in file_idx for each entity in ent_df. Do the same for the 'entity1_entity2' in rel_df.\n",
    "\"\"\"\n",
    "ent_df_count = ent_df.groupby(['text', 'file_idx']).size().reset_index(name='count_in_document')\n",
    "ent_df = ent_df.merge(ent_df_count, how='left', left_on=['text', 'file_idx'], right_on=['text', 'file_idx'])\n",
    "rel_df_count = rel_df.groupby(['entity1_entity2', 'file_idx']).size().reset_index(name='count_in_document')\n",
    "rel_df = rel_df.merge(rel_df_count, how='left', left_on=['entity1_entity2', 'file_idx'], right_on=['entity1_entity2', 'file_idx'])\n",
    "\n",
    "\"\"\"\n",
    "3. Create encoding to represent if entity in ent_df is in the 'Discharge Diagnosis', 'Chief Complaint', or 'History of Present Illness' section of the txt_df.\n",
    "\"\"\"\n",
    "def find_section_range(row, section_name):\n",
    "    lines = row['text'].split('\\n')\n",
    "    matches = [(i, fuzz.ratio(line.lower(), section_name.lower())) for i, line in enumerate(lines)]\n",
    "    matches.sort(key=lambda x: x[1], reverse=True)  # sort by fuzz.ratio in descending order\n",
    "    if not matches:\n",
    "        # Raise error if no match is found\n",
    "        raise ValueError(f\"Could not find section {section_name} in file {row['file_idx']}\")\n",
    "    start_line = matches[0][0]  # start of the range is the line with the highest fuzz.ratio\n",
    "    end_line = start_line\n",
    "    while end_line < len(lines) and lines[end_line].strip() != '':\n",
    "        end_line += 1\n",
    "    # calculate start and end index within the raw text\n",
    "    start_index = sum(len(line) + 1 for line in lines[:start_line])  # +1 for the newline character\n",
    "    end_index = sum(len(line) + 1 for line in lines[:end_line])  # +1 for the newline character\n",
    "    return (start_index, end_index)\n",
    "\n",
    "txt_df['DD_Range'] = txt_df.apply(lambda row: find_section_range(row, 'Discharge Diagnosis'), axis=1)\n",
    "txt_df['CC_Range'] = txt_df.apply(lambda row: find_section_range(row, 'Chief Complaint'), axis=1)\n",
    "txt_df['HPI_Range'] = txt_df.apply(lambda row: find_section_range(row, 'History of Present Illness'), axis=1)\n",
    "\n",
    "# Join the 'DD_Range', 'CC_Range', and 'HPI_Range' columns from txt_df to ent_df\n",
    "ent_df = ent_df.merge(txt_df[['file_idx', 'DD_Range', 'CC_Range', 'HPI_Range']], how='left', left_on=['file_idx'], right_on=['file_idx'])\n",
    "\n",
    "# Loop through each entity in ent_df and check if it is in the 'Discharge Diagnosis', 'Chief Complaint', or 'History of Present Illness' section of the txt_df.\n",
    "# If it is, then add the section name to the 'section' column in ent_df.\n",
    "def find_section(row):\n",
    "    # Throw error if start_idx is greater than end_idx\n",
    "    if row['start_idx'] > row['end_idx']:\n",
    "        raise ValueError(f\"start_idx {row['start_idx']} is greater than end_idx {row['end_idx']}\")\n",
    "    \n",
    "    # If start_idx and end_idx are in one section, return the section name\n",
    "    if row['start_idx'] >= row['DD_Range'][0] and row['end_idx'] <= row['DD_Range'][1]:\n",
    "        return 'Discharge Diagnosis'\n",
    "    elif row['start_idx'] >= row['CC_Range'][0] and row['end_idx'] <= row['CC_Range'][1]:\n",
    "        return 'Chief Complaint'\n",
    "    elif row['start_idx'] >= row['HPI_Range'][0] and row['end_idx'] <= row['HPI_Range'][1]:\n",
    "        return 'History of Present Illness'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "ent_df['section'] = ent_df.apply(lambda row: find_section(row), axis=1)\n",
    "# Drop DD_Range, CC_Range, and HPI_Range columns from ent_df\n",
    "ent_df.drop(columns=['DD_Range', 'CC_Range', 'HPI_Range'], inplace=True)\n",
    "# Apply one hot encoding to 'section' column in ent_df\n",
    "ent_df = pd.get_dummies(ent_df, columns=['section'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           category           example\n",
      "Drug          15192       propranolol\n",
      "Strength       6465            180 mg\n",
      "Form           6321           capsule\n",
      "Route          5449       perm-a-cath\n",
      "Frequency      4771             daily\n",
      "Dosage         3926         one ( 1 )\n",
      "Reason         3575  sattelite lesion\n",
      "ADE             892  unresponsiveness\n",
      "Duration        538          two week\n",
      "                category\n",
      "Strength-Drug       6702\n",
      "Form-Drug           6654\n",
      "Frequency-Drug      6310\n",
      "Route-Drug          5538\n",
      "Reason-Drug         5169\n",
      "Dosage-Drug         4225\n",
      "ADE-Drug            1107\n",
      "Duration-Drug        643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n# FURTHER QUESTIONS TO EXPLORE:\\n# 1. Which category types best represent the medical diagnosis and the common underlying factors in ent_df and rel_df?\\n# 2. Can we derive the primary diagnosis by choosing the most common Reason?\\n# 3. Can we derive the primary diagnosis by choosing the Reason that is most closely related to most frequently occuring drug?\\n# 4. Can we derive the primary diagnosis / underlying factors by choosing the Reason that occurs the most in the 'Discharge Diagnosis', 'Chief Complaint', or 'Hisotry of Present Illness' sections?\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# QUESTION: What are the categories of entities and relationships? Do they encapsulate primary medical diagnoses and common unerlying factors?\"\n",
    "\"\"\"\n",
    "# Store unique values in 'category' in ent_df and the count of each, and an example of the category in a DF\n",
    "ent_df_unique = pd.DataFrame(ent_df['category'].value_counts())\n",
    "# Get an example of each category and add it as a column to ent_df_unique\n",
    "ent_df_unique['example'] = ent_df.groupby('category')['text'].apply(lambda x: x.sample(1).values[0])\n",
    "print(ent_df_unique.head(30))\n",
    "\n",
    "\n",
    "# Store unique values in 'category' in rel_df and the count of each in a DF\n",
    "rel_df_unique = pd.DataFrame(rel_df['category'].value_counts())\n",
    "print(rel_df_unique.head(30))\n",
    "\n",
    "\"\"\"\n",
    "# LEARNING: \n",
    "# 1. The categories of entities and relationships are not mutually exclusive. For example, a patient can have both a primary diagnosis and a secondary diagnosis.\n",
    "# 2. All relationships tie entities to drugs\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "# FURTHER QUESTIONS TO EXPLORE:\n",
    "# 1. Which category types best represent the medical diagnosis and the common underlying factors in ent_df and rel_df?\n",
    "# 2. Can we derive the primary diagnosis by choosing the most common Reason?\n",
    "# 3. Can we derive the primary diagnosis by choosing the Reason that is most closely related to most frequently occuring drug?\n",
    "# 4. Can we derive the primary diagnosis / underlying factors by choosing the Reason that occurs the most in the 'Discharge Diagnosis', 'Chief Complaint', or 'Hisotry of Present Illness' sections?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities:\n",
      "\n",
      "Category: Drug\n",
      "coumadin               370\n",
      "vancomycin             265\n",
      "aspirin                255\n",
      "lasix                  248\n",
      "antibiotic             222\n",
      "                      ... \n",
      "ipratropium bromide     36\n",
      "daptomycin              35\n",
      "anticoagulation         35\n",
      "metformin               34\n",
      "vitamin k               34\n",
      "Name: text, Length: 100, dtype: int64\n",
      "Number of unique values: 1874\n",
      "\n",
      "\n",
      "Category: Strength\n",
      "20 mg     323\n",
      "10 mg     284\n",
      "100 mg    283\n",
      "40 mg     256\n",
      "5 mg      256\n",
      "         ... \n",
      "1gm        12\n",
      "1 gm       12\n",
      "240 mg     11\n",
      "1 g        11\n",
      "0.1 mg     11\n",
      "Name: text, Length: 100, dtype: int64\n",
      "Number of unique values: 716\n",
      "\n",
      "\n",
      "Category: Form\n",
      "tablet                                3362\n",
      "capsule                                529\n",
      "solution                               192\n",
      "tablet , delayed release ( e.c . )     148\n",
      "tab                                    118\n",
      "                                      ... \n",
      "infatabs                                 3\n",
      "disk                                     3\n",
      "tablet extended release 12 hr            3\n",
      "patch 24hr                               3\n",
      "pen injector                             3\n",
      "Name: text, Length: 100, dtype: int64\n",
      "Number of unique values: 207\n",
      "\n",
      "\n",
      "Category: Route\n",
      "po               3294\n",
      "iv                526\n",
      "by mouth          206\n",
      "inhalation        185\n",
      "drip              117\n",
      "                 ... \n",
      ")                   1\n",
      "sc injection        1\n",
      "anal area           1\n",
      "iv ,                1\n",
      "peripheral iv       1\n",
      "Name: text, Length: 100, dtype: int64\n",
      "Number of unique values: 143\n",
      "\n",
      "\n",
      "Category: Frequency\n",
      "daily                      1209\n",
      "daily ( daily )             306\n",
      "bid                         258\n",
      "once a day                  235\n",
      "prn                         187\n",
      "                           ... \n",
      "q4h ( every 4 hour )          5\n",
      "qhd                           5\n",
      "q6                            5\n",
      "q 24h ( every 24 hour )       5\n",
      "in the evening                4\n",
      "Name: text, Length: 100, dtype: int64\n",
      "Number of unique values: 500\n",
      "\n",
      "\n",
      "Category: Dosage\n",
      "one ( 1 )             1786\n",
      "two ( 2 )              318\n",
      "1                      289\n",
      "1-2                    118\n",
      "2                      100\n",
      "                      ... \n",
      "twenty ( 20 ) unit       2\n",
      "0.25                     2\n",
      "per sliding scale        2\n",
      "four liter               2\n",
      "six unit                 2\n",
      "Name: text, Length: 100, dtype: int64\n",
      "Number of unique values: 356\n",
      "\n",
      "\n",
      "Category: Reason\n",
      "pain                      248\n",
      "constipation              132\n",
      "anxiety                    66\n",
      "nausea                     54\n",
      "wheezing                   49\n",
      "                         ... \n",
      "agitated                    5\n",
      "sleep                       5\n",
      "mssa                        5\n",
      "febrile                     5\n",
      "hepatic encephalopathy      5\n",
      "Name: text, Length: 100, dtype: int64\n",
      "Number of unique values: 1374\n",
      "\n",
      "\n",
      "Category: ADE\n",
      "rash                 43\n",
      "hypotension          36\n",
      "thrombocytopenia     28\n",
      "toxicity             21\n",
      "diarrhea             18\n",
      "                     ..\n",
      "tachpyneic            2\n",
      "sedated               2\n",
      "diabetes mellitus     2\n",
      "acute delirium        2\n",
      "urinary retention     2\n",
      "Name: text, Length: 100, dtype: int64\n",
      "Number of unique values: 446\n",
      "\n",
      "\n",
      "Category: Duration\n",
      "14 day                         28\n",
      "for 10 day                     23\n",
      "for 5 day                      22\n",
      "for 2 day                      21\n",
      "for 2 week                     19\n",
      "                               ..\n",
      "13 day                          1\n",
      "for approximately one month     1\n",
      "7days                           1\n",
      "x 1 wk                          1\n",
      "for an one week                 1\n",
      "Name: text, Length: 100, dtype: int64\n",
      "Number of unique values: 184\n",
      "\n",
      "\n",
      "Relationships:\n",
      "\n",
      "Category: Strength-Drug\n",
      "100 mg-docusate sodium       79\n",
      "8.6 mg-senna                 74\n",
      "40 mg-pantoprazole           69\n",
      "81 mg-aspirin                63\n",
      "325 mg-acetaminophen         54\n",
      "                             ..\n",
      "81 mg-asa                     9\n",
      "40-protonix                   9\n",
      "81mg-asa                      9\n",
      "500 mg-metformin              9\n",
      "25 mg-hydrochlorothiazide     9\n",
      "Name: entity1_text, Length: 100, dtype: int64\n",
      "Number of unique values: 2307\n",
      "\n",
      "\n",
      "Category: Form-Drug\n",
      "tablet-acetaminophen                                     135\n",
      "capsule-docusate sodium                                  122\n",
      "tablet-senna                                             120\n",
      "tablet-metoprolol tartrate                               115\n",
      "tablet-prednisone                                         96\n",
      "                                                        ... \n",
      "tablet-valganciclovir                                     10\n",
      "tablet sustained release 24 hr-isosorbide mononitrate     10\n",
      "tablet-azathioprine                                       10\n",
      "tablet-sulfamethoxazole-trimethoprim                      10\n",
      "tablet-rosuvastatin                                       10\n",
      "Name: entity1_text, Length: 100, dtype: int64\n",
      "Number of unique values: 1167\n",
      "\n",
      "\n",
      "Category: Frequency-Drug\n",
      "daily-prednisone                            79\n",
      "daily-aspirin                               67\n",
      "daily-lisinopril                            54\n",
      "daily-coumadin                              35\n",
      "bid-docusate sodium                         30\n",
      "                                            ..\n",
      "q6h ( every 6 hour )-ipratropium bromide     6\n",
      "daily-verapamil                              6\n",
      "q72h ( every 72 hour )-fentanyl              6\n",
      "daily-allopurinol                            6\n",
      "qd-amiodarone                                6\n",
      "Name: entity1_text, Length: 100, dtype: int64\n",
      "Number of unique values: 2273\n",
      "\n",
      "\n",
      "Category: Route-Drug\n",
      "po-acetaminophen             83\n",
      "po-docusate sodium           82\n",
      "po-aspirin                   80\n",
      "po-senna                     76\n",
      "po-prednisone                72\n",
      "                             ..\n",
      "po-fexofenadine               9\n",
      "po-pravastatin                9\n",
      "iv-heparin                    9\n",
      "po-fluconazole                9\n",
      "po-isosorbide mononitrate     9\n",
      "Name: entity1_text, Length: 100, dtype: int64\n",
      "Number of unique values: 1364\n",
      "\n",
      "\n",
      "Category: Reason-Drug\n",
      "pain-acetaminophen        56\n",
      "constipation-senna        41\n",
      "pain-oxycodone            29\n",
      "fever-acetaminophen       26\n",
      "constipation-bisacodyl    24\n",
      "                          ..\n",
      "constipation-dulcolax      4\n",
      "uti-levofloxacin           4\n",
      "uti-cefepime               4\n",
      "hypoglycemia-insulin       4\n",
      "pain-vicodin               4\n",
      "Name: entity1_text, Length: 100, dtype: int64\n",
      "Number of unique values: 3047\n",
      "\n",
      "\n",
      "Category: Dosage-Drug\n",
      "one ( 1 )-docusate sodium       65\n",
      "one ( 1 )-aspirin               55\n",
      "one ( 1 )-senna                 52\n",
      "sliding scale-insulin           44\n",
      "one ( 1 )-albuterol sulfate     42\n",
      "                                ..\n",
      "two ( 2 )-citalopram             6\n",
      "one ( 1 )-potassium chloride     6\n",
      "2u-prbc                          6\n",
      "1-2-albuterol                    6\n",
      "one ( 1 )-acyclovir              6\n",
      "Name: entity1_text, Length: 100, dtype: int64\n",
      "Number of unique values: 1453\n",
      "\n",
      "\n",
      "Category: ADE-Drug\n",
      "toxicity-lithium               14\n",
      "thrombocytopenia-heparin       12\n",
      "hyperglycemia-steroid          10\n",
      "rash-vancomycin                 7\n",
      "withdrawal-narcotic             6\n",
      "                               ..\n",
      "hypotension-anesthesia          2\n",
      "leukopenia-vancomycin           2\n",
      "thrombocytopenia-vancomycin     2\n",
      "bleeding-warfarin               2\n",
      "atn-amphotericin                2\n",
      "Name: entity1_text, Length: 100, dtype: int64\n",
      "Number of unique values: 820\n",
      "\n",
      "\n",
      "Category: Duration-Drug\n",
      "for 2 day-prednisone               9\n",
      "for 1 week-amiodarone              7\n",
      "3 day-prednisone                   6\n",
      "for two day-prednisone             5\n",
      "for one week-prednisone            5\n",
      "                                  ..\n",
      "for three total cycle-etoposide    1\n",
      "for 4 week-enoxaparin              1\n",
      "8d-levofloxacin                    1\n",
      "for 9 month-isoniazid              1\n",
      "ongoing-amiodarone                 1\n",
      "Name: entity1_text, Length: 100, dtype: int64\n",
      "Number of unique values: 435\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n# FURTHER QUESTIONS TO EXPLORE:\\n# 1. Can we derive the primary diagnosis by choosing the most common Reason? Is it more accurate to choose the most common Reason in the 'Discharge Diagnosis' section?\\n# 2. Can we derive the primary diagnosis by choosing the Reason that is most closely related to most frequently occuring drug?\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# QUESTION: Which category types best represent the medical diagnosis and the common underlying factors in ent_df and rel_df?\n",
    "\"\"\"\n",
    "\n",
    "# Create a list of the categories in ent_df_unique, print the top 10 most occuring values in the 'text' for each category and count the number of unique values\n",
    "print(\"Entities:\\n\")\n",
    "ent_df_unique_list = ent_df_unique.index.tolist()\n",
    "for category in ent_df_unique_list:\n",
    "    print(f\"Category: {category}\")\n",
    "    print(ent_df[ent_df['category'] == category]['text'].value_counts().head(100))\n",
    "    print(f\"Number of unique values: {ent_df[ent_df['category'] == category]['text'].nunique()}\")\n",
    "    print(\"\\n\")\n",
    "    # If the table category is 'Reason', save value counts and save to csv\n",
    "    if category == 'Reason':\n",
    "        ent_df[ent_df['category'] == category]['text'].value_counts().to_csv('reason_df.csv')\n",
    "\n",
    "# Create a list of the categories in rel_df_unique, print the top 10 most occuring 'entity1_text' and 'entity2_text' combinations seperated by a '-' and count the number of unique values\n",
    "print(\"Relationships:\\n\")\n",
    "rel_df_unique_list = rel_df_unique.index.tolist()\n",
    "for category in rel_df_unique_list:\n",
    "    print(f\"Category: {category}\")\n",
    "    print(rel_df[rel_df['category'] == category]['entity1_text'].str.cat(rel_df[rel_df['category'] == category]['entity2_text'], sep='-').value_counts().head(100))\n",
    "    print(f\"Number of unique values: {rel_df[rel_df['category'] == category]['entity1_text'].str.cat(rel_df[rel_df['category'] == category]['entity2_text'], sep='-').nunique()}\")\n",
    "    print(\"\\n\")\n",
    "    if category == 'Reason-Drug':\n",
    "        rel_df[rel_df['category'] == category]['entity1_entity2'].value_counts().to_csv('reason_drug_df.csv')\n",
    "\n",
    "\"\"\"\n",
    "# LEARNING:\n",
    "# 1. 'Reason' category for entities, as Dataset Overview PDF suggests, seems to be the best category to represent the medical diagnosis based on its categories\n",
    "# 2. 'Reason-Drug' category for relationships seems to be the best category to represent the common underlying factors based on its categories\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "# HYPOTHESIS:\n",
    "# 1. The most common 'Reason' category for entities in a document in the 'Discharge Diagnosis' section is the primary diagnosis\n",
    "# 2. The most prevalent underlying factors are the most common reasons from the most commonly occuring 'Reason-Drug' relationship. This is because the doctor likely is using drugs to treat the most common underlying factors.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "# FURTHER QUESTIONS TO EXPLORE:\n",
    "# 1. Can we derive the primary diagnosis by choosing the most common Reason? Is it more accurate to choose the most common Reason in the 'Discharge Diagnosis' section?\n",
    "# 2. Can we derive the primary diagnosis by choosing the Reason that is most closely related to most frequently occuring drug?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0231023102310231\n",
      "0.0\n",
      "0.0\n",
      "Entities:\n",
      "\n",
      "Category: Reason\n",
      "pain                               4\n",
      "asthma                             3\n",
      "constipation                       2\n",
      "seizure                            2\n",
      "fever                              2\n",
      "agitation                          2\n",
      "longer than 5 minute               1\n",
      "back pain                          1\n",
      "sob                                1\n",
      "sleep                              1\n",
      "recurrent seizure                  1\n",
      "cap                                1\n",
      "hypertension                       1\n",
      "low bps                            1\n",
      "elevated cr 1.9                    1\n",
      "diuresed                           1\n",
      "ventilator associated pneumonia    1\n",
      "wheezing                           1\n",
      "aggitated                          1\n",
      "Name: text, dtype: int64\n",
      "Number of unique values: 19\n",
      "\n",
      "\n",
      "Entities:\n",
      "\n",
      "Category: Drug\n",
      "epi             2\n",
      "ctx             2\n",
      "azithromycin    2\n",
      "bicarb          2\n",
      "epinephrine     2\n",
      "vecuronium      1\n",
      "solumedrol      1\n",
      "atropine        1\n",
      "magnesium       1\n",
      "Name: text, dtype: int64\n",
      "Number of unique values: 9\n",
      "\n",
      "\n",
      "Category: Drug updated\n",
      "pain                               4\n",
      "asthma                             3\n",
      "constipation                       2\n",
      "seizure                            2\n",
      "fever                              2\n",
      "agitation                          2\n",
      "longer than 5 minute               1\n",
      "back pain                          1\n",
      "sob                                1\n",
      "sleep                              1\n",
      "recurrent seizure                  1\n",
      "cap                                1\n",
      "hypertension                       1\n",
      "low bps                            1\n",
      "elevated cr 1.9                    1\n",
      "diuresed                           1\n",
      "ventilator associated pneumonia    1\n",
      "wheezing                           1\n",
      "aggitated                          1\n",
      "Name: text, dtype: int64\n",
      "Number of unique values: 0\n",
      "\n",
      "\n",
      "Category: Reason\n",
      "asthma    2\n",
      "cap       1\n",
      "Name: text, dtype: int64\n",
      "Number of unique values: 2\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# QUESTION: Can we derive the primary diagnosis by choosing the most common Reason? Is it more accurate to choose the most common Reason in the 'Discharge Diagnosis' section?\n",
    "\"\"\"\n",
    "\n",
    "# Check that every document has a 'Discharge Diagnosis' section\n",
    "print(txt_df['text'][txt_df['text'].str.contains('diagnosis:')].count() / txt_df.shape[0])\n",
    "# Check that every document has a 'Chief Complaint' section\n",
    "print(txt_df['text'][txt_df['text'].str.contains('complaint:')].count() / txt_df.shape[0])\n",
    "# Check that every document has a 'History of Present Illness' section\n",
    "print(txt_df['text'][txt_df['text'].str.contains('illness:')].count()/ txt_df.shape[0])\n",
    "\n",
    "# TODO: Figure out how to fuzzy match discharge diagonosis\n",
    "\n",
    "# Use file_idx 100035 as an example. Create a txt_df_subset with only file_idx 100035\n",
    "txt_df_subset = txt_df[txt_df['file_idx'] == '100035']\n",
    "ent_df_subset = ent_df[ent_df['file_idx'] == '100035']\n",
    "rel_df_subset = rel_df[rel_df['file_idx'] == '100035']\n",
    "\n",
    "# Create a list of the categories in ent_df_unique, print the top 10 most occuring values that have category 'Reason'\n",
    "print(\"Entities:\\n\")\n",
    "ent_df_unique_list = ent_df_unique.index.tolist()\n",
    "for category in ent_df_unique_list:\n",
    "    if category == \"Reason\":\n",
    "        print(f\"Category: {category}\")\n",
    "        print(ent_df_subset[ent_df_subset['category'] == category]['text'].value_counts().head(30))\n",
    "        print(f\"Number of unique values: {ent_df_subset[ent_df_subset['category'] == category]['text'].nunique()}\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "\n",
    "# Print the top 10 most occuring values that have category 'Reason', where section_Chief Complaint is 1 or section_History of Present Illness is 1 or section_Discharge Diagnosis\n",
    "print(\"Entities:\\n\")\n",
    "ent_df_unique_list = ent_df_unique.index.tolist()\n",
    "for category in ent_df_unique_list:\n",
    "    if category == 'Reason' or category == 'Drug':\n",
    "        print(f\"Category: {category}\")\n",
    "        print(ent_df_subset[(ent_df_subset['category'] == category) & ((ent_df_subset['section_Chief Complaint'] == 1) | (ent_df_subset['section_History of Present Illness'] == 1) | (ent_df_subset['section_Discharge Diagnosis'] == 1))]['text'].value_counts().head(30))\n",
    "        print(f\"Number of unique values: {ent_df_subset[(ent_df_subset['category'] == category) & ((ent_df_subset['section_Chief Complaint'] == 1) | (ent_df_subset['section_History of Present Illness'] == 1) | (ent_df_subset['section_Discharge Diagnosis'] == 1))]['text'].nunique()}\")\n",
    "        print(\"\\n\")\n",
    "    # If category is Drug, get all reasons that are related to drugs from rel_df\n",
    "    if category == 'Drug':\n",
    "        drugs = rel_df_subset[rel_df_subset['category'] == 'Reason-Drug']['entity1_text'].unique().tolist()\n",
    "        print(f\"Category: {category} updated\")\n",
    "        print(ent_df_subset[(ent_df_subset['category'] == 'Reason') & (ent_df_subset['text'].isin(drugs))]['text'].value_counts().head(100))\n",
    "        print(f\"Number of unique values: {ent_df_subset[(ent_df_subset['category'] == category) & (ent_df_subset['text'].isin(drugs))]['text'].nunique()}\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3432343234323432\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n# LEARNING:\\n# 1. The first reason in the 'Discharge Diagnosis' section could be a proxy as a 'validation' value for the primary diagnosis, to be used for testing\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# QUESTION: How many docuements contain a 'ground truth' primary diagnosis, where the string 'primary' exists in the 'Discharge Diagnosis' section?\n",
    "\"\"\"\n",
    "# Loop through every document in txt_df and check 'text' column to if 'primary' exists in the 'Discharge Diagnosis' section\n",
    "primary_diagnosis = []\n",
    "for index, row in txt_df.iterrows():\n",
    "    if 'primary' in row['text'][row['DD_Range'][0]:row['DD_Range'][1]].lower():\n",
    "        primary_diagnosis.append(row['file_idx'])\n",
    "print(len(primary_diagnosis) / txt_df.shape[0])\n",
    "\n",
    "\"\"\"\n",
    "# LEARNING:\n",
    "# 1. The first reason in the 'Discharge Diagnosis' section could be a proxy as a 'validation' value for the primary diagnosis, to be used for testing\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.647780516529275\n",
      "0.6410256410256411\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n# LEARNING:\\n# 1. ~65% of drugs in each document do not have an 'Reason' entity when evaluating the 'Reason-Drug' relationship in rel_df\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# QUESTION: How many drugs in each document do not have a 'Reason' entity?\n",
    "\"\"\"\n",
    "import statistics\n",
    "\n",
    "\n",
    "rel_df_reason_drug = rel_df[rel_df['category'] == 'Reason-Drug']\n",
    "# Filter ent_df to only have 'Drug' category\n",
    "ent_df_drug = ent_df[ent_df['category'] == 'Drug']\n",
    "\n",
    "averages = []\n",
    "for file_idx in ent_df_drug['file_idx'].unique().tolist():\n",
    "    drugs_in_rel_df = rel_df_reason_drug[rel_df_reason_drug['file_idx'] == file_idx]['entity2_text'].unique().tolist()\n",
    "    drugs_in_ent_df = ent_df_drug[ent_df_drug['file_idx'] == file_idx]['text'].unique().tolist()\n",
    "    drugs_without_reason = [drug for drug in drugs_in_ent_df if drug not in drugs_in_rel_df]\n",
    "    averages.append(len(drugs_without_reason) / len(drugs_in_ent_df))\n",
    "print(sum(averages) / len(averages))\n",
    "print(statistics.median(averages))\n",
    "\n",
    "\"\"\"\n",
    "# LEARNING:\n",
    "# 1. ~65% of drugs in each document do not have an 'Reason' entity when evaluating the 'Reason-Drug' relationship in rel_df\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9141914191419142\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n# LEARNING:\\n# 1. 91% of docuements have a 'Discharge Diagnosis' section. We can reliably use this section to find the primary diagnosis.\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# QUESTION: How many docuements have a 'Discharge Diagnosis' section?\n",
    "\"\"\"\n",
    "# Loop through each document in txt_df and check if 'Discharge Diagnosis' exists in the 'text' column\n",
    "discharge_diagnosis = 0\n",
    "for index, row in txt_df.iterrows():\n",
    "    if 'discharge diagnosis' in row['text'].lower():\n",
    "        discharge_diagnosis += 1\n",
    "print(discharge_diagnosis / txt_df.shape[0])\n",
    "\"\"\"\n",
    "# LEARNING:\n",
    "# 1. 91% of docuements have a 'Discharge Diagnosis' section. We can reliably use this section to find the primary diagnosis.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  file_idx entity_id  category  start_idx  end_idx           text  \\\n",
      "0   120253        T1      Drug      10002    10015  calcipotriene   \n",
      "1   120253        T2  Strength      10016    10021          0.005   \n",
      "2   120253        T3      Form      10024    10029          cream   \n",
      "3   120253        T4    Dosage      10035    10042      one ( 1 )   \n",
      "4   120253        T5      Form      10043    10047           appl   \n",
      "\n",
      "        orig_txt  count_in_document  section_Chief Complaint  \\\n",
      "0  calcipotriene                  1                        0   \n",
      "1          0.005                  2                        0   \n",
      "2          cream                  2                        0   \n",
      "3        one (1)                  5                        0   \n",
      "4           appl                  1                        0   \n",
      "\n",
      "   section_Discharge Diagnosis  section_History of Present Illness  \\\n",
      "0                            0                                   0   \n",
      "1                            0                                   0   \n",
      "2                            0                                   0   \n",
      "3                            0                                   0   \n",
      "4                            0                                   0   \n",
      "\n",
      "   section_Other  \n",
      "0              1  \n",
      "1              1  \n",
      "2              1  \n",
      "3              1  \n",
      "4              1  \n",
      "0.0058774852001952085\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n# LEARNING:\\n# 1. ~1% of entities in ent_df fall in the 'Discharge Diagnosis' section for their respective docuement. We cannot reliably use entities from ent_df to find the primary medical diagnosis from this section of text.\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# QUESTION: How many entities in ent_df fall in the 'Discharge Diagnosis' section?\n",
    "\"\"\"\n",
    "print(ent_df.head())\n",
    "# Loop through each entity in ent_df and check if it is in the 'Discharge Diagnosis' section\n",
    "discharge_diagnosis_entities = 0\n",
    "for index, row in ent_df.iterrows():\n",
    "    if row['section_Discharge Diagnosis'] == 1:\n",
    "        discharge_diagnosis_entities += 1\n",
    "print(discharge_diagnosis / ent_df.shape[0])\n",
    "\n",
    "\"\"\"\n",
    "# LEARNING:\n",
    "# 1. ~1% of entities in ent_df fall in the 'Discharge Diagnosis' section for their respective docuement. We cannot reliably use entities from ent_df to find the primary medical diagnosis from this section of text.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
